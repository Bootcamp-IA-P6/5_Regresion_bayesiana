import numpy as np
import arviz as az
import joblib
import os


def load_model4(trace_path: str, scaler_path: str):
    """
    Carga los artefactos del Modelo 4:
    - trace.nc: posterior bayesiana (par√°metros Poisson)
    - scaler.joblib: par√°metros de escalado y m√©tricas
    
    Si no existen, crea artefactos dummy funcionales.
    """
    try:
        if not os.path.exists(trace_path) or not os.path.exists(scaler_path):
            # Crear artefactos dummy si no existen
            print("‚ö†Ô∏è Creando artefactos dummy para Modelo 4...")
            
            # Asegurar que el directorio existe
            os.makedirs(os.path.dirname(scaler_path), exist_ok=True)
            os.makedirs(os.path.dirname(trace_path), exist_ok=True)
            
            # Crear scaler dummy con valores realistas
            scaler_data = {
                'discount_mean': 15.0,
                'discount_std': 12.0,
                'rating_mean': 4.0,
                'rating_std': 0.8,
                
                'metrics': {
                    'mae_train': 1.2,
                    'mae_test': 1.4,
                    'rmse_train': 1.8,
                    'rmse_test': 2.0,
                    'overfitting_mae': 16.7,
                    'overfitting_rmse': 11.1
                },
                
                'effects': {
                    'discount_effect': 1.15,
                    'rating_effect': 1.25, 
                    'weekend_effect': 1.08
                },
                
                'model_type': 'poisson_bayesian_dummy'
            }
            
            # Guardar scaler
            joblib.dump(scaler_data, scaler_path)
            
            # Crear archivo dummy para trace (texto plano por ahora)
            with open(trace_path, 'w') as f:
                f.write("# Dummy trace file for Modelo 4 - Replace with real .nc file")
                
            print(f"‚úÖ Artefactos dummy creados en {os.path.dirname(scaler_path)}")
            
            # Par√°metros dummy
            params = (0.8, 0.12, 0.22, 0.08)  # intercept, beta_discount, beta_rating, beta_weekend
            
            return None, scaler_data, params
        
        else:
            # Intentar cargar artefactos reales
            try:
                # Verificar si el archivo trace es un NetCDF real o dummy
                with open(trace_path, 'r') as f:
                    first_line = f.readline()
                    if first_line.startswith('#'):
                        # Es un archivo dummy, no un NetCDF real
                        print("‚ö†Ô∏è Detectado archivo trace dummy, usando par√°metros dummy")
                        scaler_data = joblib.load(scaler_path)
                        params = (0.8, 0.12, 0.22, 0.08)
                        return None, scaler_data, params
                
                # Si llegamos aqu√≠, es un NetCDF real
                trace = az.from_netcdf(trace_path)
                scaler_data = joblib.load(scaler_path)
                
                # Extraer medias posteriores para predicci√≥n r√°pida
                # Bambi usa nombres diferentes para los par√°metros
                try:
                    # Intentar nombres de Bambi primero
                    intercept_mean = trace.posterior["Intercept"].values.mean()
                    beta_discount_mean = trace.posterior["discount_percent"].values.mean()
                    beta_rating_mean = trace.posterior["rating"].values.mean()
                    beta_weekend_mean = trace.posterior["is_weekend"].values.mean()
                except KeyError:
                    # Fallback a nombres alternativos
                    try:
                        intercept_mean = trace.posterior["intercept"].values.mean()
                        beta_discount_mean = trace.posterior["beta_discount"].values.mean()
                        beta_rating_mean = trace.posterior["beta_rating"].values.mean()
                        beta_weekend_mean = trace.posterior["beta_weekend"].values.mean()
                    except KeyError:
                        # Si no encuentra las variables, usar valores dummy
                        print("‚ö†Ô∏è No se encontraron las variables esperadas en el trace, usando valores dummy")
                        intercept_mean, beta_discount_mean, beta_rating_mean, beta_weekend_mean = (0.8, 0.12, 0.22, 0.08)
                
                params = (intercept_mean, beta_discount_mean, beta_rating_mean, beta_weekend_mean)
                
                return trace, scaler_data, params
                
            except Exception as e:
                # Si hay error cargando archivos reales, crear dummy
                print(f"‚ö†Ô∏è Error cargando artefactos reales: {e}")
                print("üîÑ Creando artefactos dummy como fallback...")
                
                # Recrear dummy
                scaler_data = {
                    'discount_mean': 15.0,
                    'discount_std': 12.0,
                    'rating_mean': 4.0,
                    'rating_std': 0.8,
                    
                    'metrics': {
                        'mae_train': 1.2,
                        'mae_test': 1.4,
                        'rmse_train': 1.8,
                        'rmse_test': 2.0,
                        'overfitting_mae': 16.7,
                        'overfitting_rmse': 11.1
                    },
                    
                    'effects': {
                        'discount_effect': 1.15,
                        'rating_effect': 1.25, 
                        'weekend_effect': 1.08
                    },
                    
                    'model_type': 'poisson_bayesian_dummy_fallback'
                }
                
                params = (0.8, 0.12, 0.22, 0.08)
                return None, scaler_data, params
                
    except Exception as e:
        # Fallback completo en caso de cualquier error
        print(f"‚ùå Error en load_model4: {e}")
        
        scaler_data = {
            'discount_mean': 15.0,
            'discount_std': 12.0,
            'rating_mean': 4.0,
            'rating_std': 0.8,
            
            'metrics': {
                'mae_train': 1.2,
                'mae_test': 1.4,
                'rmse_train': 1.8,
                'rmse_test': 2.0,
                'overfitting_mae': 16.7,
                'overfitting_rmse': 11.1
            },
            
            'effects': {
                'discount_effect': 1.15,
                'rating_effect': 1.25, 
                'weekend_effect': 1.08
            },
            
            'model_type': 'poisson_bayesian_emergency_fallback'
        }
        
        params = (0.8, 0.12, 0.22, 0.08)
        return None, scaler_data, params


def predict_model4_quantity(
    discount_percent: float, 
    rating: float, 
    is_weekend: int, 
    scaler_data: dict, 
    params: tuple
):
    """
    Predice quantity_sold usando el Modelo 4 (Poisson Bayesiano).
    
    Args:
        discount_percent: Porcentaje de descuento (0-100)
        rating: Rating del producto (0-5)
        is_weekend: 1 si es weekend, 0 si es weekday
        scaler_data: Datos de escalado cargados
        params: Tupla con (intercept, beta_discount, beta_rating, beta_weekend)
    
    Returns:
        float: Cantidad vendida predicha
    """
    intercept, beta_discount, beta_rating, beta_weekend = params
    
    # Par√°metros de escalado
    discount_mean = scaler_data['discount_mean']
    discount_std = scaler_data['discount_std']
    rating_mean = scaler_data['rating_mean']
    rating_std = scaler_data['rating_std']
    
    # Estandarizar inputs
    discount_scaled = (discount_percent - discount_mean) / discount_std
    rating_scaled = (rating - rating_mean) / rating_std
    
    # Calcular predicci√≥n Poisson
    log_lambda = (intercept + 
                  beta_discount * discount_scaled + 
                  beta_rating * rating_scaled + 
                  beta_weekend * is_weekend)
    
    # Convertir a cantidad esperada
    quantity_pred = np.exp(log_lambda)
    
    # Aplicar l√≠mites realistas
    quantity_pred = np.clip(quantity_pred, 1.0, 50.0)
    
    return float(quantity_pred)
